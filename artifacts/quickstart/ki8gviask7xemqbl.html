---
title: 模型训练
toc: content
dateModified: 2023-08-01T09:02:22.000Z
---
<!doctype html><div class="lake-content" typography="classic"><h3 id="F78BF"><span class="ne-text">逻辑回归</span></h3><p id="uc6b20690" class="ne-p"><span class="ne-text" style="color: #117CEE">作用：基于秘密分享的 MPC 逻辑回归训练。</span></p><p id="u92d6ddcc" class="ne-p"><span class="ne-text">●上游连接输出宽表/联合表的组件输出桩。<br /></span><span class="ne-text">●输出桩1输出联合模型，通常连接下游模型预测组件或 P-Value 组件。<br /></span><span class="ne-text">●输出桩2输出模型参数，不参与下游连线。</span></p><h4 id="SbVDJ"><span class="ne-text">参数说明</span></h4><table id="KbHOd" class="ne-table" style="width: 748px"><tbody><tr style="height: 33px"><td width="187"><p id="u05705b0d" class="ne-p"><span class="ne-text">参数名称</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u92ad1b26" class="ne-p"><span class="ne-text">参数描述</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u8938baec" class="ne-p"><span class="ne-text">参数值可选项</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u2e0d79c4" class="ne-p"><span class="ne-text">默认值</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="uca159019" class="ne-p"><span class="ne-text">特征列</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="uc6fa326e" class="ne-p"><span class="ne-text">仅支持 double 型，不支持带空值的特征列。若特征列含空值/异常值，请勿选择（经异常值处理或分箱后可使用）。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u72671f6f" class="ne-p"><span class="ne-text">该联合表的所有特征列。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u388e469a" class="ne-p"><span class="ne-text">无</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="uc56245cf" class="ne-p"><span class="ne-text">标签列</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u5b815953" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u119edfd2" class="ne-p"><span class="ne-text">上游输出的特征列中选择。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u1b34b97b" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u1cb74788" class="ne-p"><span class="ne-text">迭代次数</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u3bd67b7b" class="ne-p"><span class="ne-text">epoch，使用训练集的全部数据对模型进行一次完成训练。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u10e653ca" class="ne-p"><span class="ne-text">支持输入[1,1000]的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ub72d9cc8" class="ne-p"><span class="ne-text">20</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="ub4ac2fa6" class="ne-p"><span class="ne-text">训练批数据量</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="uad2ba106" class="ne-p"><span class="ne-text">batch_size，指将训练集分成若干批，每批样本的大小。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ub4f7c0fb" class="ne-p"><span class="ne-text">支持输入[1,10000]的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u86763481" class="ne-p"><span class="ne-text">512</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="ude1c0989" class="ne-p"><span class="ne-text">学习率配置</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u29f59004" class="ne-p"><span class="ne-text">支持学习率随迭代轮数增加而变化。（通常是减小，以便模型收敛）</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u6c845f87" class="ne-p"><span class="ne-text">contant（恒定学习率）、step decay（等比变化）、cosine decay（基于 cosine 函数变化）。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ue91a04aa" class="ne-p"><span class="ne-text">contant（恒定学习率）</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="uc761a530" class="ne-p"><span class="ne-text">decay rate（学习率配置选择等比变化时需填写的参数）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="ud12d2aa8" class="ne-p"><span class="ne-text">learning_rate(n)=learning_rate(0) * pow(decay_rate, floor(n/decay_epoch))</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u781a183e" class="ne-p"><span class="ne-text">范围：(0,1]。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u25eeaec7" class="ne-p"><span class="ne-text">1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u377f2175" class="ne-p"><span class="ne-text">decay_epochs（学习率配置选择等比变化时需填写的参数）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u8b8e42a8" class="ne-p"><span class="ne-text">learning_rate(n)=learning_rate(0) * pow(decay_rate, floor(n/decay_epoch))</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u73642420" class="ne-p"><span class="ne-text">大于0的数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u91051457" class="ne-p"><span class="ne-text">1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u837360cf" class="ne-p"><span class="ne-text">alpha（学习率配置选择cosine decay时填写）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u7258c57b" class="ne-p"><span class="ne-text">cosine decay 超参，详细定义见算法文档。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u2f4a499e" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u63f79a67" class="ne-p"><span class="ne-text">0</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u20bd708a" class="ne-p"><span class="ne-text">decay_epochs（学习率配置选择cosine decay时填写）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u17dd39d9" class="ne-p"><span class="ne-text">cosine decay 超参，详细定义见算法文档。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u18741909" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u403a9264" class="ne-p"><span class="ne-text">20</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="udd1a8ea0" class="ne-p"><span class="ne-text">学习率</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u88de9123" class="ne-p"><span class="ne-text">leaning_rate，当学习率设置的过小时，收敛过程将变得十分缓慢；而当学习率设置的过大时，梯度可能会在最小值附近来回震荡，甚至可能无法收敛。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ua153ea77" class="ne-p"><span class="ne-text">支持输入[0,10000]的正数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ubac37d3b" class="ne-p"><span class="ne-text">0.1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u02555bc4" class="ne-p"><span class="ne-text">L2正则系数</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u9659e167" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u636b4513" class="ne-p"><span class="ne-text">支持输入[0,100]的正数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="uddf709c8" class="ne-p"><span class="ne-text">0</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u3680f3be" class="ne-p"><span class="ne-text">sigmoid 函数拟合方法</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u94b6471a" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="uf447f0e3" class="ne-p"><span class="ne-text">泰勒一阶、Minmax 一阶密态三分段。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u7a8e7a4c" class="ne-p"><span class="ne-text">泰勒一阶</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u3e1b6122" class="ne-p"><span class="ne-text">是否输出模型参数信息</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="uea8c8e9b" class="ne-p"><span class="ne-text"><br /></span></p></td><td width="186"><p id="udb630c6b" class="ne-p"><span class="ne-text">是、否。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="uc066afb1" class="ne-p"><span class="ne-text">是</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u9e304e4d" class="ne-p"><span class="ne-text">use_ring_128</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="ub690a26d" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u4678a414" class="ne-p"><span class="ne-text">是、否。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u44594049" class="ne-p"><span class="ne-text">是</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u7c050f78" class="ne-p"><span class="ne-text">fxp_bits</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u1be9a680" class="ne-p"><span class="ne-text">64位引擎，建议使用16-18,128位引擎，建议使用20-28。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ub5a47f09" class="ne-p"><span class="ne-text">0-30的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ud3991dbe" class="ne-p"><span class="ne-text" style="color: rgb(38, 38, 38)">24</span><span class="ne-text" style="color: rgb(38, 38, 38)"><br /></span></p></td></tr></tbody></table><h3 id="qijNb"><span class="ne-text" style="color: rgb(38, 38, 38)">线性回归</span></h3><p id="uc8e5fe01" class="ne-p"><span class="ne-text" style="color: #117CEE">作用：基于秘密分享的 MPC 线性回归训练。</span></p><p id="u83deb20e" class="ne-p"><span class="ne-text" style="color: rgb(38, 38, 38)">●上游连接输出宽表/联合表的组件输出桩。<br /></span><span class="ne-text" style="color: rgb(38, 38, 38)">●输出桩1输出联合模型，通常连接下游模型预测组件或 P-Value 组件。<br /></span><span class="ne-text" style="color: rgb(38, 38, 38)">●输出桩2输出模型参数，不参与下游连线。</span></p><h4 id="XouS8"><span class="ne-text">参数说明</span></h4><table id="kUrUM" class="ne-table" style="width: 748px"><tbody><tr style="height: 33px"><td width="187"><p id="u5701d087" class="ne-p"><span class="ne-text">参数名称</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u8d42d063" class="ne-p"><span class="ne-text">参数描述</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u460118a6" class="ne-p"><span class="ne-text">参数值可选项</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u070f51e3" class="ne-p"><span class="ne-text">默认值</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="ubbf692b7" class="ne-p"><span class="ne-text">特征列</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u63884679" class="ne-p"><span class="ne-text">仅支持 double 型，不支持带空值的特征列。若特征列含空值/异常值，请勿选择。（经异常值处理或分箱后可使用）</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="udc1016a5" class="ne-p"><span class="ne-text">该联合表的所有特征列。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u0d03e008" class="ne-p"><span class="ne-text">无</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u47c78449" class="ne-p"><span class="ne-text">标签列</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u6a588b92" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u89992197" class="ne-p"><span class="ne-text">上游输出的特征列中选择。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ufdc403b5" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="ufbbeb595" class="ne-p"><span class="ne-text">迭代次数</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u343d8eb8" class="ne-p"><span class="ne-text">epoch,使用训练集的全部数据对模型进行一次完成训练。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ub8fe34af" class="ne-p"><span class="ne-text">支持输入[1,1000]的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u0729eba1" class="ne-p"><span class="ne-text">20</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="ub102a9dd" class="ne-p"><span class="ne-text">训练批数据量</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u407c73c1" class="ne-p"><span class="ne-text">batch_size，指将训练集分成若干批，每批样本的大小。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u0c09cf57" class="ne-p"><span class="ne-text">支持输入[1,10000]的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ua993936b" class="ne-p"><span class="ne-text">512</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u1f9ee261" class="ne-p"><span class="ne-text">学习率配置</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u0a35a52f" class="ne-p"><span class="ne-text">支持学习率随迭代轮数增加而变化。（通常是减小，以便模型收敛）</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u6c1e78b9" class="ne-p"><span class="ne-text">contant（恒定学习率）、step decay（等比变化）、cosine decay（基于 cosine 函数变化）</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u28c8da9b" class="ne-p"><span class="ne-text">contant（恒定学习率）</span><span class="ne-text"><br /></span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u5f2f24c0" class="ne-p"><span class="ne-text">decay rate（学习率配置选择等比变化时需填写的参数）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u4e39e723" class="ne-p"><span class="ne-text">learning_rate(n)=learning_rate(0)*pow(decay_rate, floor(n/decay_epoch))</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u666845e8" class="ne-p"><span class="ne-text">范围：(0,1]。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u634b816d" class="ne-p"><span class="ne-text">1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u05eaf21d" class="ne-p"><span class="ne-text">decay_epochs（学习率配置选择等比变化时需填写的参数）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="ua2203fb9" class="ne-p"><span class="ne-text">learning_rate(n)=learning_rate(0)*pow(decay_rate, floor(n/decay_epoch))</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u786a6a04" class="ne-p"><span class="ne-text">大于0的数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u76f1a25c" class="ne-p"><span class="ne-text">1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u6e562f61" class="ne-p"><span class="ne-text">alpha（学习率配置选择cosine decay时填写）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u387b3326" class="ne-p"><span class="ne-text">cosine decay 超参，详细定义见算法文档。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u79f7e26d" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="ua599cf8e" class="ne-p"><span class="ne-text">0</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="uc448fddc" class="ne-p"><span class="ne-text">decay_epochs（学习率配置选择cosine decay时填写）</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u3c9bd682" class="ne-p"><span class="ne-text">cosine decay 超参，详细定义见算法文档。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="uca1c1f1e" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="uac727db2" class="ne-p"><span class="ne-text">20</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u2a3cc5e5" class="ne-p"><span class="ne-text">学习率</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u47e406af" class="ne-p"><span class="ne-text">leaning_rate，当学习率设置的过小时，收敛过程将变得十分缓慢；而当学习率设置的过大时，梯度可能会在最小值附近来回震荡，甚至可能无法收敛。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="uab4ee53b" class="ne-p"><span class="ne-text">支持输入[0,10000]的正数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u1532b303" class="ne-p"><span class="ne-text">0.1</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u0aebf188" class="ne-p"><span class="ne-text">L2正则系数</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="uff2622c2" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ua36b0607" class="ne-p"><span class="ne-text">支持输入[0,100]的正数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u5deba8b0" class="ne-p"><span class="ne-text">0</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u8306fa94" class="ne-p"><span class="ne-text">sigmoid 函数拟合方法</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="udb25b2bf" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u37fd156b" class="ne-p"><span class="ne-text">泰勒一阶、Minmax 一阶密态三分段。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u888a1e92" class="ne-p"><span class="ne-text">泰勒一阶</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u9546e94f" class="ne-p"><span class="ne-text">是否输出模型参数信息</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u625735a7" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u4ef78018" class="ne-p"><span class="ne-text">是、否。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u7902f740" class="ne-p"><span class="ne-text">是</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="uc787ab2b" class="ne-p"><span class="ne-text">use_ring_128</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u5c781522" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="ud5b8e39f" class="ne-p"><span class="ne-text">是、否。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u3b1333b2" class="ne-p"><span class="ne-text">是</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="187"><p id="u578c1be8" class="ne-p"><span class="ne-text">fxp_bits</span><span class="ne-text"><br /></span></p></td><td width="187"><p id="u8857bde3" class="ne-p"><span class="ne-text">64位引擎，建议使用16-18,128位引擎，建议使用20-28。</span><span class="ne-text"><br /></span></p></td><td width="186"><p id="u7c9c0a52" class="ne-p"><span class="ne-text">0-30的整数。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u4bd5ef6c" class="ne-p"><span class="ne-text">24</span><span class="ne-text"><br /></span></p></td></tr></tbody></table><h3 id="bjUSF"><span class="ne-text" style="color: rgb(38, 38, 38)">模型预测</span></h3><p id="u012a37e4" class="ne-p"><span class="ne-text" style="color: #117CEE">作用：模型离线批量打分</span></p><p id="u195cb073" class="ne-p"><span class="ne-text">●上游桩1连接输出宽表/联合表的组件输出桩，用于预测数据的输入，桩2输入模型，通常模型的预处理需要和预测数据的预处理保持一致。<br /></span><span class="ne-text">●输出预测结果，通常连接评估组件，如二分类评估、PVA、回归模型评估。</span></p><h4 id="Ykcta"><span class="ne-text">参数说明</span></h4><table id="ERKCo" class="ne-table" style="width: 776px"><tbody><tr style="height: 33px"><td width="158"><p id="ufdeb021d" class="ne-p"><span class="ne-text">参数名称</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="ucb272bdd" class="ne-p"><span class="ne-text">参数描述</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="u19b52607" class="ne-p"><span class="ne-text">参数值可选项</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u991ee690" class="ne-p"><span class="ne-text">默认值</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="158"><p id="u103e21c7" class="ne-p"><span class="ne-text">标签列</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="u9f0d1c41" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="u91a7c114" class="ne-p"><span class="ne-text">输入标签列。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u65323453" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="158"><p id="u617d12ed" class="ne-p"><span class="ne-text">预测结果列名</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="u2487439e" class="ne-p"><span class="ne-text">为您模型预测产出的分所在列命名。</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="u0df27f07" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u7cc875df" class="ne-p"><span class="ne-text">prediction</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="158"><p id="u0acb56d5" class="ne-p"><span class="ne-text">原样添加到结果列</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="u83612e27" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="u3f7a7904" class="ne-p"><span class="ne-text">选择桩1输入的特征列。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u2da87f85" class="ne-p"><span class="ne-text">/</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="158"><p id="u1b4559f1" class="ne-p"><span class="ne-text">高级配置-模型预测结果保存方式</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="u3b5ff98a" class="ne-p"><span class="ne-text">可选择保存到长效文件目录、保存到临时文件目录、自定义。</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="u2f1452e8" class="ne-p"><span class="ne-text">长效文件目录、保存到临时文件目录、自定义。</span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u1d65d69a" class="ne-p"><span class="ne-text">长效文件目录</span><span class="ne-text"><br /></span></p></td></tr><tr style="height: 33px"><td width="158"><p id="ud4438307" class="ne-p"><span class="ne-text">高级配置-保存目录</span><span class="ne-text"><br /></span></p></td><td width="205"><p id="ua3a1bc54" class="ne-p"><span class="ne-text">选择保存到长效文件目录、保存到临时文件目录自动填充目录，不可更改。</span><span class="ne-text"><br /></span></p></td><td width="225"><p id="uab370b79" class="ne-p"><span class="ne-text">●</span><span class="ne-text">长效文件目录、保存到临时文件目录：默认填充，不可更改</span><span class="ne-text"><br /></span><span class="ne-text">●</span><span class="ne-text">自定义组件：用户填写。</span><span class="ne-text"><br /></span><span class="ne-text"><br /></span></p></td><td width="188"><p id="u8041fc39" class="ne-p"><span class="ne-text" style="color: rgb(38, 38, 38)">/</span><span class="ne-text" style="color: rgb(38, 38, 38)"><br /></span></p></td></tr></tbody></table><h3 id="ekcPz"><span class="ne-text">XGB二分类</span></h3><p id="ub7a25eed" class="ne-p"><span class="ne-text">作用：</span><span class="ne-text" style="color: rgba(0, 0, 0, 0.85); font-size: 14px">基于同态加密或秘密分享的MPC 树模型训练</span></p><p id="uf9e1d3e7" class="ne-p"><span class="ne-text" style="color: rgba(0, 0, 0, 0.85); font-size: 14px"></span></p><h3 id="eMb3P"><span class="ne-text">XGB回归</span></h3><p id="u454e8d16" class="ne-p"><span class="ne-text" style="color: rgba(0, 0, 0, 0.85); font-size: 14px">作用：基于同态加密或秘密分享的MPC 树模型训练</span></p><p id="uf110e699" class="ne-p"><span class="ne-text"></span></p><p id="uf9b7ac75" class="ne-p"><br></p><p id="u12b6d040" class="ne-p"><span class="ne-text"></span></p></div>