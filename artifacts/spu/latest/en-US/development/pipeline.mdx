---
git_download_url: https://github.com/secretflow/spu/raw/207435da0de58cf3352ad4c7c73d97f9ef3ba9ba/docs/development/pipeline.rst
git_last_modified_commit: b0fe367bd75ec9fe770245e9a45fe002665b79b9
git_last_modified_time: '2023-03-07T10:23:08+08:00'
git_origin_url: https://github.com/secretflow/spu/blob/207435da0de58cf3352ad4c7c73d97f9ef3ba9ba/docs/development/pipeline.rst
git_owner: secretflow
git_repo: spu
git_revision_commit: 207435da0de58cf3352ad4c7c73d97f9ef3ba9ba
git_revision_time: '2024-01-08T11:48:55+08:00'
---

:target{#spu-pipeline}

# SPU Pipeline

Recall that SPU could be treated as a [virtual device](basic_concepts.mdx#machine-model). When working with a (virtual or physical) device, we need several steps.

1. infeed code to it
2. infeed data to it
3. trigger it to run
4. get result from it

This page describes details of each step.

:target{#overview}

## Overview

Before diving into the details, let’s first take a closer look of SPU pipeline, it’s something like this:

<figure id="id1">
  ![](../_assets/pipeline.svg)

  <figcaption>
    code and data pipeline
  </figcaption>
</figure>

:target{#compilation}

## Compilation

The vertical part depicts the compilation pipeline, from top to bottom.

1. Programmer writes code in AI frameworks(like TensorFlow/JAX).
2. AI frontend traces the DAG, and emits as XLA IR.
3. SPU compiler takes XLA IR, and compiles it to SPU IR, the format that SPU runtime understands.

For more details, please see [SPU Compiler](compiler.mdx) for details.

:target{#data-pipeline}

## Data pipeline

The horizontal part depicts the data pipeline, from left to right.

1. Data providers use [SPU io](../reference/py_api.mdx#runtime-io) module to encrypt input data.
   - For SPU MPC backend, <em>encrypt</em> means to split plaintext data into shares.
   - For floating point data, encoding to fixed-point may be also required.
2. The encrypted data is send to [SPU runtime](../reference/py_api.mdx#runtime-setup).
3. The output data is fetched <em>result owner</em>, and decrypted by the [SPU io](../reference/py_api.mdx#runtime-io) module.

:target{#just-in-time}

## Just in time

Jit is short for [Just-in-time compilation](https://en.wikipedia.org/wiki/Just-in-time_compilation), with this approach, the compiler can get more information, such as input shapes, than in [AOT mode](https://en.wikipedia.org/wiki/Ahead-of-time_compilation). Jit may introduce more evaluation overhead, but it’s really trivial in secure computation setting.

In SPU, jit has more benefits since the backend engine may be orders of magnitude faster if it knows the <em>visibility</em> of data. For example, when multiplying two secrets, the backend MPC engine may involve expensive <em>beaver triple</em> progress, but when one of the inputs (of multiply) is public known to all parties, the operation will be much faster. So we should <em>mark</em> as much data as possible to be <em>public</em> (if it doesn’t need to be protected), and tell the compiler these information.

So, SPU compilation normally happens after all data infeed is done, and <cite>just in time</cite> before the real evaluation.
