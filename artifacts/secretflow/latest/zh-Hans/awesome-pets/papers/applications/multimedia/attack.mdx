---
git_download_url: https://github.com/secretflow/secretflow/raw/f2c46f98224a42f29bca20751a569bbfac39f750/docs/awesome-pets/papers/applications/multimedia/attack.md
git_last_modified_commit: 77f923e99e01e9757cc7ebaeb92e80aec6eb4711
git_last_modified_time: '2023-07-31T16:54:37+08:00'
git_origin_url: https://github.com/secretflow/secretflow/blob/f2c46f98224a42f29bca20751a569bbfac39f750/docs/awesome-pets/papers/applications/multimedia/attack.md
git_owner: secretflow
git_repo: secretflow
git_revision_commit: f2c46f98224a42f29bca20751a569bbfac39f750
git_revision_time: '2024-01-03T19:41:12+08:00'
---

:target{#attack-methods}

# Attack Methods

- MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation.
  <em>Sanjay Kariyappaï¼ŒAtul Prakash, Moinuddin K Qureshi</em>
  CVPR 2021, [eprint](https://ieeexplore.ieee.org/document/9577631)
- Data-Free Model Extraction.
  <em>Truong Jean-Baptiste, Maini Pratyush, Walls Robert J, Papernot Nicolas</em>
  CVPR 2021, [eprint](https://arxiv.org/abs/2011.14779)
- Model Inversion Attack by Integration of Deep Generative Models: Privacy-Sensitive Face Generation From a Face Recognition System.
  <em>Mahdi Khosravy, Kazuaki Nakamura, Yuki Hirose, Naoko Nitta, Noboru Babaguchi</em>
  TIFS 2022, [eprint](https://dl.acm.org/doi/abs/10.1109/TIFS.2022.3140687)
- Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks.
  <em>Struppek Lukas, Hintersdorf Dominik, Correia Antonio De Almeida, Adler Antonia, Kersting Kristian</em>
  ICML 2022, [eprint](https://arxiv.org/pdf/2201.12179.pdf)
- See through gradients: Image batch recovery via gradinversion.
  <em>Yin Hongxu, Mallya Arun, Vahdat Arash, Alvarez Jose M, Kautz Jan, Molchanov Pavlo</em>
  CVPR 2021, [eprint](https://arxiv.org/pdf/2007.13635.pdf)
- ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning.
  <em>Jingtao Li, Adnan Siraj Rakin, Xing Chen, Zhezhi He, Deliang Fan, Chaitali Chakrabarti</em>
  CVPR 2022, [eprint](https://openaccess.thecvf.com/content/CVPR2022/html/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.html)
- Soteria: Provable defense against privacy leakage in federated learning from representation perspective.
  <em>Jingwei Sun, Ang Li, Binghui Wang, Huanrui Yang, Hai Li, Yiran Chen</em>
  CVPR 2021, [eprint](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.pdf)
- Label-Only Membership Inference Attack.
  <em>Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, Nicolas Papernot</em>
  ICML 2021, [eprint](http://proceedings.mlr.press/v139/choquette-choo21a/choquette-choo21a.pdf)
- Bilateral Dependency Optimization: Defending Against Model-inversion Attacks.
  <em>Xiong Peng, Feng Liu, Jingfen Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han</em>
  KDD 2022, [eprint](https://arxiv.org/abs/2206.05483)
- Feature inference attack on model predictions in vertical federated learning.
  <em>Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi</em>
  ICDE 2021, [eprint](https://arxiv.org/abs/2010.10152)
