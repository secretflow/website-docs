---
git_commit: 215ee402b76decfeb01e97c0861cab9f5ec3f823
git_download_url: https://github.com/secretflow/secretflow/raw/215ee402b76decfeb01e97c0861cab9f5ec3f823/docs/user_guide/mpc_ml/decision_tree.rst
git_origin_url: https://github.com/secretflow/secretflow/blob/215ee402b76decfeb01e97c0861cab9f5ec3f823/docs/user_guide/mpc_ml/decision_tree.rst
git_owner: secretflow
git_repo: secretflow
git_timestamp: '2023-12-06T20:08:22+08:00'
---

:target{#decision-trees}

# å†³ç­–æ ‘æ¨¡å‹

SecretFlowä½¿ç”¨å¤šæ–¹å®‰å…¨è®¡ç®—çš„ç§˜å¯†åˆ†äº«æŠ€æœ¯å®ç°äº†å¯è¯å®‰å…¨çš„æ¢¯åº¦ä¸‹é™å†³ç­–æ ‘æ¨¡å‹ [`Xgb()`](../../source/secretflow.ml.boost.ml.boost.ss_xgb_v.mdx#secretflow.ml.boost.ss_xgb_v.model.Xgb "secretflow.ml.boost.ss_xgb_v.model.Xgb") ï¼Œç›®å‰æ”¯æŒçº¿æ€§å›å½’é—®é¢˜è®­ç»ƒå’ŒäºŒåˆ†ç±»é—®é¢˜è®­ç»ƒã€‚

:target{#dataset-settings}

## æ•°æ®è®¾å®š

å‚ç›´åˆ’åˆ†çš„æ•°æ®é›†

- æ‰€æœ‰æ•°æ®æ–¹çš„æ ·æœ¬ä¸€è‡´
- ä½†æ˜¯æ‹¥æœ‰æ ·æœ¬çš„ä¸åŒç‰¹å¾
- åªæœ‰ä¸€æ–¹æŒæœ‰æ ‡ç­¾

![](../../_assets/v_dataset.png):target{#xgboost-training-algorithm}

## XGBoost è®­ç»ƒç®—æ³•

è¯¦ç»†åŸç†åŠæ¨å¯¼å¯è§ [å®˜æ–¹æ–‡æ¡£](https://xgboost.readthedocs.io/en/stable/tutorials/model.html) ã€‚å•æ£µæ ‘åˆ†è£‚çš„ä¸»è¦è¿‡ç¨‹å¦‚ä¸‹ï¼š

- é¢„è®¡ç®—ï¼šæ ¹æ®æŸå¤±å‡½æ•°å®šä¹‰ã€æ ·æœ¬æ ‡ç­¾ã€å½“å‰é¢„æµ‹å€¼ï¼Œè®¡ç®—æ¯ä¸ªæ ·æœ¬å¯ä»¥æ±‚å¾—å…¶ä¸€é˜¶å¯¼ <InlineMath>$g_{i}$</InlineMath> å’ŒäºŒé˜¶å¯¼  <InlineMath>$h_{i}$</InlineMath>
- ç»“ç‚¹åˆ†è£‚ï¼šé€šè¿‡æšä¸¾æ‰€æœ‰åˆ†è£‚æ–¹æ¡ˆï¼Œé€‰å‡ºå¸¦æ¥æœ€ä¼˜å¢ç›Šå€¼çš„æ–¹å¼æ‰§è¡Œåˆ†è£‚ã€‚åˆ†è£‚æ–¹æ¡ˆåŒ…å«åˆ†è£‚ç‰¹å¾å’Œåˆ†è£‚é˜ˆå€¼ï¼Œå¯ä»¥å°†å½“å‰ç»“ç‚¹æ ·æœ¬é›†åˆ <InlineMath>$I$</InlineMath> åˆ†è£‚ä¸º å·¦å­æ ‘æ ·æœ¬é›†åˆ <InlineMath>$I_{L}$</InlineMath> å’Œå³å­æ ‘æ ·æœ¬é›†åˆ <InlineMath>$I_{R}$</InlineMath>ï¼Œ å¹¶ç”±å¦‚ä¸‹å…¬å¼è®¡ç®—å‡ºæ­¤åˆ†è£‚æ–¹æ¡ˆçš„å¢ç›Šå€¼ï¼š

  ![](../../_assets/gain_formula.png)

  å…¶ä¸­ï¼š<InlineMath>$\lambda$</InlineMath> å’Œ <InlineMath>$\gamma$</InlineMath> åˆ†åˆ«ä¸ºå¶èŠ‚ç‚¹æ•°å’Œå¶èŠ‚ç‚¹æƒé‡çš„æƒ©ç½šå› å­ã€‚
- æƒé‡è®¡ç®—ï¼šç”±è½å…¥è¯¥ç»“ç‚¹çš„æ ·æœ¬è®¡ç®—å¾—åˆ°ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

  ![](../../_assets/weight_formula.png)

å›å½’é—®é¢˜å’Œåˆ†ç±»é—®é¢˜çš„è®­ç»ƒæµç¨‹æ˜¯ç›¸åŒçš„ï¼Œé™¤äº†ï¼š

1. æŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼ˆå›å½’-MSEï¼Œåˆ†ç±»-Logloss)ã€‚
2. åˆ†ç±»é—®é¢˜éœ€è¦å°†é¢„æµ‹å€¼é€šè¿‡sigmoidå‡½æ•°è½¬åŒ–ä¸ºæ¦‚ç‡ã€‚

:target{#ss-xgb-training}

## SS-XGB è®­ç»ƒç®—æ³•

SS-XGB [`Xgb()`](../../source/secretflow.ml.boost.ml.boost.ss_xgb_v.mdx#secretflow.ml.boost.ss_xgb_v.model.Xgb "secretflow.ml.boost.ss_xgb_v.model.Xgb") ä½¿ç”¨ç§˜å¯†åˆ†äº«è®¡ç®—åˆ†è£‚å¢ç›Šå€¼å’Œå¶æƒé‡ã€‚

æˆ‘ä»¬ä½¿ç”¨ç§˜å¯†åˆ†äº«åè®®æä¾›çš„åŠ /ä¹˜ç­‰æ“ä½œæ¥å®ç°å®‰å…¨çš„å¤šæ–¹è”åˆè®¡ç®—ã€‚ç‰¹åˆ«éœ€è¦å…³æ³¨çš„é—®é¢˜æ˜¯ï¼šå¦‚ä½•åœ¨è®¡ç®—åˆ†æ¡¶åŠ å’Œæ—¶ï¼Œä¸æ³„æ¼ä»»ä½•æ ·æœ¬åˆ†å¸ƒç›¸å…³çš„ä¿¡æ¯ã€‚

é€šè¿‡å¼•å…¥ä¸€ä¸ªå¯†æ€ä¸‹çš„å‘é‡ğ‘†å°±å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

![](../../_assets/indicator_vecto.jpg)

å‘é‡ğ‘†ä¸­æ ‡è®°ä¸º1çš„æ ·æœ¬æ˜¯è¢«é€‰ä¸­çš„æ ·æœ¬éœ€è¦åŠ å’Œï¼Œ0ç›¸åã€‚ä¸ºäº†ä¿è¯æ ·æœ¬åˆ†å¸ƒä¸æ³„æ¼ï¼Œè¿™ä¸ªå‘é‡ä¹Ÿæ˜¯é€šè¿‡ç§˜å¯†åˆ†äº«åè®®ä¿æŠ¤çš„ã€‚åœ¨ç§˜å¯†åˆ†äº«åè®®çš„ä¿æŠ¤ä¸‹ï¼Œè®¡ç®—å‘é‡ğ‘†å’Œæ¢¯åº¦å‘é‡çš„å†…ç§¯ï¼Œå³å¯å¾—åˆ°æ¢¯åº¦åœ¨åˆ†æ¡¶å†…çš„ç´¯åŠ å’Œã€‚

é€šè¿‡è¿™ä¸ªæ–¹æ³•æˆ‘ä»¬å°±å¯ä»¥ä¿æŠ¤æ ·æœ¬çš„åˆ†å¸ƒä¿¡æ¯ä¸æ³„æ¼ã€‚æ›´å¤šçš„ç®—æ³•ç»†èŠ‚å’Œå®‰å…¨åˆ†æï¼š[Large-Scale Secure XGB for Vertical Federated Learning](https://arxiv.org/pdf/2005.08479.pdf)

:target{#example}

## ç”¨ä¾‹

åœ¨æœ¬ç¤ºä¾‹ä¸­ä½¿ç”¨å•èŠ‚ç‚¹æ¨¡å¼åšç¤ºèŒƒã€‚é›†ç¾¤æ¨¡å¼çš„éƒ¨ç½²æ–¹å¼ï¼š [Deployment](../../getting_started/deployment.html.mdx)

APIè¯¦æƒ…ï¼š[`Xgb()`](../../source/secretflow.ml.boost.ml.boost.ss_xgb_v.mdx#secretflow.ml.boost.ss_xgb_v.model.Xgb "secretflow.ml.boost.ss_xgb_v.model.Xgb")

```python
import sys
import time
import logging

import secretflow as sf
from secretflow.ml.boost.ss_xgb_v import Xgb
from secretflow.device.driver import wait, reveal
from secretflow.data import FedNdarray, PartitionWay
from secretflow.data.split import train_test_split
import numpy as np
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score, classification_report


# init log
logging.basicConfig(stream=sys.stdout, level=logging.INFO)

# init all nodes in local Standalone Mode.
sf.init(['alice', 'bob', 'carol'], address='local')

# init PYU, the Python Processing Unit, process plaintext in each node.
alice = sf.PYU('alice')
bob = sf.PYU('bob')
carol = sf.PYU('carol')

# init SPU, the Secure Processing Unit,
#           process ciphertext under the protection of a multi-party secure computing protocol
spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob', 'carol']))

# read data in each party
def read_x(start, end):
    from sklearn.datasets import load_breast_cancer
    x = load_breast_cancer()['data']
    return x[:, start:end]

def read_y():
    from sklearn.datasets import load_breast_cancer
    return load_breast_cancer()['target']

# alice / bob / carol each hold one third of the features of the data
v_data = FedNdarray(
    partitions={
        alice: alice(read_x)(0, 10),
        bob: bob(read_x)(10, 20),
        carol: carol(read_x)(20, 30),
    },
    partition_way=PartitionWay.VERTICAL,
)
# Y label belongs to alice
label_data = FedNdarray(
    partitions={alice: alice(read_y)()},
    partition_way=PartitionWay.VERTICAL,
)
# wait IO finished
wait([p.data for p in v_data.partitions.values()])
wait([p.data for p in label_data.partitions.values()])
# split train data and test date
random_state = 1234
split_factor = 0.8
v_train_data, v_test_data = train_test_split(v_data, train_size=split_factor, random_state=random_state)
v_train_label, v_test_label= train_test_split(label_data, train_size=split_factor, random_state=random_state)
# run SS-XGB
xgb = Xgb(spu)
start = time.time()
params = {
    # for more detail, see Xgb API doc
    'num_boost_round': 5,
    'max_depth': 5,
    'learning_rate': 0.1,
    'sketch_eps': 0.08,
    'objective': 'logistic',
    'reg_lambda': 0.1,
    'subsample': 1,
    'colsample_by_tree': 1,
    'base_score': 0.5,
}
model = xgb.train(params, v_train_data,v_train_label)
logging.info(f"train time: {time.time() - start}")

# Do predict
start = time.time()
# Now the result is saved in the spu by ciphertext
spu_yhat = model.predict(v_test_data)
# reveal for auc, acc and classification report test.
yhat = reveal(spu_yhat)
logging.info(f"predict time: {time.time() - start}")
y = reveal(v_test_label.partitions[alice])
# get the area under curve(auc) score of classification
logging.info(f"auc: {roc_auc_score(y, yhat)}")
binary_class_results = np.where(yhat>0.5, 1, 0)
# get the accuracy score of classification
logging.info(f"acc: {accuracy_score(y, binary_class_results)}")
# get the report of classification
print("classification report:")
print(classification_report(y, binary_class_results))
```
