---
git_download_url: https://github.com/secretflow/secretflow/raw/215ee402b76decfeb01e97c0861cab9f5ec3f823/docs/tutorial/numpy_with_spu.ipynb
git_last_modified_commit: a06f2ac1994afc5af895824e2000a848dd1e4673
git_last_modified_time: '2023-08-22T13:04:56+08:00'
git_origin_url: https://github.com/secretflow/secretflow/blob/215ee402b76decfeb01e97c0861cab9f5ec3f823/docs/tutorial/numpy_with_spu.ipynb
git_owner: secretflow
git_repo: secretflow
git_revision_commit: 215ee402b76decfeb01e97c0861cab9f5ec3f823
git_revision_time: '2023-12-06T20:08:22+08:00'
---

:target{#Privacy-Preserving-Scientific-Computing-with-NumPy-in-SPU}

# Privacy-Preserving Scientific Computing with NumPy in SPU

NumPy is one of the most popular tool for scientific computing. It is so common that we could find lots of equivalents of NumPy in other languages like [xtensor](https://xtensor.readthedocs.io/en/latest/) and [Gonum](https://www.gonum.org/). So we can’t help thinking whether we could express computation with NumPy-like APIs in privacy-preserving settings since everyone loves NumPy.

Luckily, with the power of [JAX](https://jax.readthedocs.io/en/latest/) NumPy package, we could easily accomplish this goal. In this tutorial, we would go through: - The relation between JAX and SPU - Write a Jittable JAX Program - Execute JAX Program with SPU

:target{#The-relation-between-JAX-and-SPU}

## The relation between JAX and SPU

:target{#TL;DR}

### TL;DR

SPU actually consists of two components - Compiler and Runtime. SPU Runtime could only execute [PPHlo](https://www.secretflow.org.cn/docs/spu/en/reference/pphlo_doc.html). One example of PPHlo kernel is [pphlo.add](https://www.secretflow.org.cn/docs/spu/en/reference/pphlo_doc.html#pphlo-add-mlir-pphlo-addop). Actually we just feed PPHlo programs to SPU Runtime directly to execute MPC programs in some internal applications when the logic is extremely simple and clear.

SPU compiler could translate [XLA](https://www.tensorflow.org/xla) programs to [PPHlo](https://www.secretflow.org.cn/docs/spu/en/reference/pphlo_doc.html). You could check “Supported” XLA ops in [this documentation](https://www.secretflow.org.cn/docs/spu/en/reference/xla_status.html). You may find XLA ops are very similar to PPHlo ops in most cases. It seems we still couldn’t write XLA programs by hand. You are absolutely correct. If you happen to check
[here](https://www.tensorflow.org/xla#xla_frontends), you should find actually there are lot’s of AI frameworks which could emit XLA programs without your effort, including:

- TensorFLow
- Pytorch
- JAX

Let’s go through each step to have a look at different programs!

:target{#JAX-Program}

#### JAX Program

The below is a jax program to add an array and a scalar. It should make sense to you if you are familiar with NumPy.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[1]:" stderr={false} type="input">
    ```python
    import jax
    import numpy as np


    def simple_add(x, y):
        return jax.numpy.add(x, y)


    simple_add(np.array([[1, 2], [3, 4]]), 4)
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[1]:" stderr={false} type="output">
    <pre>
      {"Array([[5, 6],\n       [7, 8]], dtype=int32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#XLA-Program}

#### XLA Program

Let’s check what the XLA program for this JAX program looks like. JAX provides [xla\_computation](https://jax.readthedocs.io/en/latest/_autosummary/jax.xla_computation.html) to convert JAX programs to XLA programs.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[3]:" stderr={false} type="input">
    ```python
    c = jax.xla_computation(simple_add)(np.array([[1, 2], [3, 4]]), 4)

    c.as_hlo_text()
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[3]:" stderr={false} type="output">
    <pre>
      {"'HloModule xla_computation_simple_add, entry_computation_layout={(s32[2,2]{1,0}, s32[])->(s32[2,2]{1,0})}\\n\\nENTRY main.6 {\\n  Arg_0.1 = s32[2,2]{1,0} parameter(0)\\n  Arg_1.2 = s32[] parameter(1)\\n  broadcast.3 = s32[2,2]{1,0} broadcast(Arg_1.2), dimensions={}\\n  add.4 = s32[2,2]{1,0} add(Arg_0.1, broadcast.3)\\n  ROOT tuple.5 = (s32[2,2]{1,0}) tuple(add.4)\\n}\\n\\n'\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

You should be aware of the following facts:

- shape and dtype is fixed in XLA program like <strong>s32\[2,2]\{1,0}</strong> in each command.
- an implicit <strong>broadcast</strong> op is inserted before <strong>add</strong> op.

:target{#PPHlo-Program}

#### PPHlo Program

Lastly, let’s check the PPHlo program for this XLA program. <strong>spu.compile</strong> could convert XLA programs to PPHlo programs.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[4]:" stderr={false} type="input">
    ```python
    import spu
    import spu.spu_pb2 as spu_pb2

    source = spu_pb2.CompilationSource()
    source.ir_txt = c.as_serialized_hlo_module_proto()
    source.input_visibility.extend([spu.Visibility.VIS_SECRET, spu.Visibility.VIS_SECRET])
    source.ir_type = spu_pb2.SourceIRType.XLA

    pphlo = spu.compile(source, spu_pb2.CompilerOptions())

    pphlo
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[4]:" stderr={false} type="output">
    <pre>
      {"b'module @xla_computation_simple_add attributes {mhlo.cross_program_prefetches = [], mhlo.dynamic_parameter_bindings = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {\\n  func.func @main(%arg0: tensor<2x2x!pphlo.sec<i32>>, %arg1: tensor<!pphlo.sec<i32>>) -> tensor<2x2x!pphlo.sec<i32>> {\\n    %0 = \"pphlo.broadcast\"(%arg1) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<!pphlo.sec<i32>>) -> tensor<2x2x!pphlo.sec<i32>>\\n    %1 = \"pphlo.add\"(%arg0, %0) : (tensor<2x2x!pphlo.sec<i32>>, tensor<2x2x!pphlo.sec<i32>>) -> tensor<2x2x!pphlo.sec<i32>>\\n    return %1 : tensor<2x2x!pphlo.sec<i32>>\\n  }\\n}\\n'\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

You may find the PPHlo program is identical to XLA program. The only differences are:

- You have to provide the input visibility to SPU compiler, i.e. <strong>\[spu.Visibility.VIS\_SECRET, spu.Visibility.VIS\_SECRET]</strong> in our case.
- Comparing to XLA program, <strong>Visibility</strong> is an extra attribute to all variables in PPHlo program like <strong>tensor\<2x2x!pphlo.sec></strong> means this is a secret 2x2 i32 tensor.

SPU compiler would deduce visibility in each step, let’s modify input visibility and check what would happen.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[5]:" stderr={false} type="input">
    ```python
    source = spu_pb2.CompilationSource()
    source.ir_txt = c.as_serialized_hlo_module_proto()
    source.input_visibility.extend([spu.Visibility.VIS_SECRET, spu.Visibility.VIS_PUBLIC])
    source.ir_type = spu_pb2.SourceIRType.XLA

    pphlo = spu.compile(source, spu_pb2.CompilerOptions())

    pphlo
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[5]:" stderr={false} type="output">
    <pre>
      {"b'module @xla_computation_simple_add attributes {mhlo.cross_program_prefetches = [], mhlo.dynamic_parameter_bindings = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {\\n  func.func @main(%arg0: tensor<2x2x!pphlo.sec<i32>>, %arg1: tensor<!pphlo.pub<i32>>) -> tensor<2x2x!pphlo.sec<i32>> {\\n    %0 = \"pphlo.broadcast\"(%arg1) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<!pphlo.pub<i32>>) -> tensor<2x2x!pphlo.pub<i32>>\\n    %1 = \"pphlo.add\"(%arg0, %0) : (tensor<2x2x!pphlo.sec<i32>>, tensor<2x2x!pphlo.pub<i32>>) -> tensor<2x2x!pphlo.sec<i32>>\\n    return %1 : tensor<2x2x!pphlo.sec<i32>>\\n  }\\n}\\n'\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#From-JAX-to-SPU}

### From JAX to SPU

So this is the whole story. 1. You write a JAX program in Python. 2. Then you could turn JAX program to XLA program with the first-party API from JAX, i.e. jax.xla\_computation. 3. Afterwards, SPU compiler could transfer XLA program to PPHlo program - the only language could be understood by SPU Runtime. 4. In the end, the PPHlo program is sent to SPU Runtimes and executed.

In SecretFlow, we have implemented some helper methods so that you could just write a JAX program in the beginning, we would take care of the remaining steps for you.

:target{#Write-a-Jittable-JAX-Program}

## Write a Jittable JAX Program

Jittable means a JAX program could be Just In Time (JIT) compilation into XLA program. So only when a JAX program is Jittable, it then could be possibly executed by SPU.

Since SPU doesn’t support all XLA operators, even a JAX program is jittable, SPU runtime still could refuse to execute.

:target{#JAX-NumPy-Package}

### JAX NumPy Package

We could use these [NumPy-like APIs](https://jax.readthedocs.io/en/latest/jax.numpy.html) from JAX. JAX NumPy APIs are very similar to original ones, while - JAX NumPy arrays are immutable, so you have to use <strong>ndarray.at</strong> instead of in-place array updates - You have to provide some extra args to make the method call jittable(we would discuss this later).

And actually SPU doesn’t support all JAX NumPy operators, please also check [this documentation](http://www.secretflow.org.cn/docs/spu/en/reference/np_op_status.html). We are updating this document promptly and we have listed the current status of each operators.

Next, we are going to write some JAX Numpy programs.

:target{#Euclidean-Distance}

### Euclidean Distance

Just one-line code we could compute Euclidean Distance of two points.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[5]:" stderr={false} type="input">
    ```python
    def euclidean_distance(p1, p2):
        return jax.numpy.linalg.norm(p1 - p2)
    ```
  </Notebook.CodeArea>
</Notebook.Cell>

Let’s check whether it is jittable by <strong>jax.jit</strong>. You could also use <strong>jax.xla\_computation</strong> for testing as well.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[6]:" stderr={false} type="input">
    ```python
    euclidean_distance_jit = jax.jit(euclidean_distance)

    print(euclidean_distance_jit(np.array([0, 0]), np.array([3, 4])))


    # or
    print(
        (
            jax.xla_computation(euclidean_distance)(np.array([0, 0]), np.array([3, 4]))
        ).as_hlo_text()
    )
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="" stderr={false} type="output">
    <pre>
      {"5.0\nHloModule xla_computation_euclidean_distance, entry_computation_layout={(s32[2]{0},s32[2]{0})->(f32[])}\n\nregion_0.4 {\n  Arg_0.5 = f32[] parameter(0)\n  Arg_1.6 = f32[] parameter(1)\n  ROOT add.7 = f32[] add(Arg_0.5, Arg_1.6)\n}\n\nnorm.8 {\n  Arg_0.9 = s32[2]{0} parameter(0)\n  convert.11 = f32[2]{0} convert(Arg_0.9)\n  multiply.12 = f32[2]{0} multiply(convert.11, convert.11)\n  constant.10 = f32[] constant(0)\n  reduce.13 = f32[] reduce(multiply.12, constant.10), dimensions={0}, to_apply=region_0.4\n  ROOT sqrt.14 = f32[] sqrt(reduce.13)\n}\n\nENTRY main.17 {\n  Arg_0.1 = s32[2]{0} parameter(0)\n  Arg_1.2 = s32[2]{0} parameter(1)\n  subtract.3 = s32[2]{0} subtract(Arg_0.1, Arg_1.2)\n  call.15 = f32[] call(subtract.3), to_apply=norm.8\n  ROOT tuple.16 = (f32[]) tuple(call.15)\n}\n\n\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#Area-of-a-Simple-Polygon}

### Area of a Simple Polygon

Given a list of Cartesian coordinates of vertices of a simply polygon, we could calculate the area by [Shoelace formula](https://en.wikipedia.org/wiki/Shoelace_formula).

<Notebook.Cell>
  <Notebook.CodeArea prompt="[7]:" stderr={false} type="input">
    ```python
    import jax.numpy as jnp


    def area_of_simple_polygon(vertices):
        area = 0
        for i in range(0, vertices.shape[0]):
            a = jnp.expand_dims(vertices[i, :], axis=0)
            b = jnp.expand_dims(vertices[(i + 1) % vertices.shape[0], :], axis=0)
            x = jax.numpy.concatenate((a, b))
            x_t = jax.numpy.transpose(x)
            area += 0.5 * jax.numpy.linalg.det(x_t)
        return area


    vertices = np.array([[1, 6], [3, 1], [7, 2], [4, 4], [8, 5]])

    area_of_simple_polygon(vertices)
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[7]:" stderr={false} type="output">
    <pre>
      {"Array(16.5, dtype=float32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

Let’s check whether <strong>area\_of\_simple\_polygon</strong> is jittable.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[8]:" stderr={false} type="input">
    ```python
    print(jax.xla_computation(area_of_simple_polygon)(vertices).as_hlo_text())
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="" stderr={false} type="output">
    <pre>
      {"HloModule xla_computation_area_of_simple_polygon, entry_computation_layout={(s32[5,2]{1,0})->(f32[])}\n\ndet.7 {\n  Arg_0.8 = s32[2,2]{1,0} parameter(0)\n  convert.9 = f32[2,2]{1,0} convert(Arg_0.8)\n  slice.10 = f32[1,1]{1,0} slice(convert.9), slice={[0:1], [0:1]}\n  reshape.11 = f32[] reshape(slice.10)\n  slice.12 = f32[1,1]{1,0} slice(convert.9), slice={[1:2], [1:2]}\n  reshape.13 = f32[] reshape(slice.12)\n  multiply.14 = f32[] multiply(reshape.11, reshape.13)\n  slice.15 = f32[1,1]{1,0} slice(convert.9), slice={[0:1], [1:2]}\n  reshape.16 = f32[] reshape(slice.15)\n  slice.17 = f32[1,1]{1,0} slice(convert.9), slice={[1:2], [0:1]}\n  reshape.18 = f32[] reshape(slice.17)\n  multiply.19 = f32[] multiply(reshape.16, reshape.18)\n  ROOT subtract.20 = f32[] subtract(multiply.14, multiply.19)\n}\n\ndet_0.27 {\n  Arg_0.28 = s32[2,2]{1,0} parameter(0)\n  convert.29 = f32[2,2]{1,0} convert(Arg_0.28)\n  slice.30 = f32[1,1]{1,0} slice(convert.29), slice={[0:1], [0:1]}\n  reshape.31 = f32[] reshape(slice.30)\n  slice.32 = f32[1,1]{1,0} slice(convert.29), slice={[1:2], [1:2]}\n  reshape.33 = f32[] reshape(slice.32)\n  multiply.34 = f32[] multiply(reshape.31, reshape.33)\n  slice.35 = f32[1,1]{1,0} slice(convert.29), slice={[0:1], [1:2]}\n  reshape.36 = f32[] reshape(slice.35)\n  slice.37 = f32[1,1]{1,0} slice(convert.29), slice={[1:2], [0:1]}\n  reshape.38 = f32[] reshape(slice.37)\n  multiply.39 = f32[] multiply(reshape.36, reshape.38)\n  ROOT subtract.40 = f32[] subtract(multiply.34, multiply.39)\n}\n\ndet_1.48 {\n  Arg_0.49 = s32[2,2]{1,0} parameter(0)\n  convert.50 = f32[2,2]{1,0} convert(Arg_0.49)\n  slice.51 = f32[1,1]{1,0} slice(convert.50), slice={[0:1], [0:1]}\n  reshape.52 = f32[] reshape(slice.51)\n  slice.53 = f32[1,1]{1,0} slice(convert.50), slice={[1:2], [1:2]}\n  reshape.54 = f32[] reshape(slice.53)\n  multiply.55 = f32[] multiply(reshape.52, reshape.54)\n  slice.56 = f32[1,1]{1,0} slice(convert.50), slice={[0:1], [1:2]}\n  reshape.57 = f32[] reshape(slice.56)\n  slice.58 = f32[1,1]{1,0} slice(convert.50), slice={[1:2], [0:1]}\n  reshape.59 = f32[] reshape(slice.58)\n  multiply.60 = f32[] multiply(reshape.57, reshape.59)\n  ROOT subtract.61 = f32[] subtract(multiply.55, multiply.60)\n}\n\ndet_2.69 {\n  Arg_0.70 = s32[2,2]{1,0} parameter(0)\n  convert.71 = f32[2,2]{1,0} convert(Arg_0.70)\n  slice.72 = f32[1,1]{1,0} slice(convert.71), slice={[0:1], [0:1]}\n  reshape.73 = f32[] reshape(slice.72)\n  slice.74 = f32[1,1]{1,0} slice(convert.71), slice={[1:2], [1:2]}\n  reshape.75 = f32[] reshape(slice.74)\n  multiply.76 = f32[] multiply(reshape.73, reshape.75)\n  slice.77 = f32[1,1]{1,0} slice(convert.71), slice={[0:1], [1:2]}\n  reshape.78 = f32[] reshape(slice.77)\n  slice.79 = f32[1,1]{1,0} slice(convert.71), slice={[1:2], [0:1]}\n  reshape.80 = f32[] reshape(slice.79)\n  multiply.81 = f32[] multiply(reshape.78, reshape.80)\n  ROOT subtract.82 = f32[] subtract(multiply.76, multiply.81)\n}\n\ndet_3.90 {\n  Arg_0.91 = s32[2,2]{1,0} parameter(0)\n  convert.92 = f32[2,2]{1,0} convert(Arg_0.91)\n  slice.93 = f32[1,1]{1,0} slice(convert.92), slice={[0:1], [0:1]}\n  reshape.94 = f32[] reshape(slice.93)\n  slice.95 = f32[1,1]{1,0} slice(convert.92), slice={[1:2], [1:2]}\n  reshape.96 = f32[] reshape(slice.95)\n  multiply.97 = f32[] multiply(reshape.94, reshape.96)\n  slice.98 = f32[1,1]{1,0} slice(convert.92), slice={[0:1], [1:2]}\n  reshape.99 = f32[] reshape(slice.98)\n  slice.100 = f32[1,1]{1,0} slice(convert.92), slice={[1:2], [0:1]}\n  reshape.101 = f32[] reshape(slice.100)\n  multiply.102 = f32[] multiply(reshape.99, reshape.101)\n  ROOT subtract.103 = f32[] subtract(multiply.97, multiply.102)\n}\n\nENTRY main.108 {\n  Arg_0.1 = s32[5,2]{1,0} parameter(0)\n  slice.3 = s32[1,2]{1,0} slice(Arg_0.1), slice={[0:1], [0:2]}\n  slice.4 = s32[1,2]{1,0} slice(Arg_0.1), slice={[1:2], [0:2]}\n  concatenate.5 = s32[2,2]{1,0} concatenate(slice.3, slice.4), dimensions={0}\n  transpose.6 = s32[2,2]{0,1} transpose(concatenate.5), dimensions={1,0}\n  call.21 = f32[] call(transpose.6), to_apply=det.7\n  constant.2 = f32[] constant(0.5)\n  multiply.22 = f32[] multiply(call.21, constant.2)\n  slice.23 = s32[1,2]{1,0} slice(Arg_0.1), slice={[1:2], [0:2]}\n  slice.24 = s32[1,2]{1,0} slice(Arg_0.1), slice={[2:3], [0:2]}\n  concatenate.25 = s32[2,2]{1,0} concatenate(slice.23, slice.24), dimensions={0}\n  transpose.26 = s32[2,2]{0,1} transpose(concatenate.25), dimensions={1,0}\n  call.41 = f32[] call(transpose.26), to_apply=det_0.27\n  multiply.42 = f32[] multiply(call.41, constant.2)\n  add.43 = f32[] add(multiply.22, multiply.42)\n  slice.44 = s32[1,2]{1,0} slice(Arg_0.1), slice={[2:3], [0:2]}\n  slice.45 = s32[1,2]{1,0} slice(Arg_0.1), slice={[3:4], [0:2]}\n  concatenate.46 = s32[2,2]{1,0} concatenate(slice.44, slice.45), dimensions={0}\n  transpose.47 = s32[2,2]{0,1} transpose(concatenate.46), dimensions={1,0}\n  call.62 = f32[] call(transpose.47), to_apply=det_1.48\n  multiply.63 = f32[] multiply(call.62, constant.2)\n  add.64 = f32[] add(add.43, multiply.63)\n  slice.65 = s32[1,2]{1,0} slice(Arg_0.1), slice={[3:4], [0:2]}\n  slice.66 = s32[1,2]{1,0} slice(Arg_0.1), slice={[4:5], [0:2]}\n  concatenate.67 = s32[2,2]{1,0} concatenate(slice.65, slice.66), dimensions={0}\n  transpose.68 = s32[2,2]{0,1} transpose(concatenate.67), dimensions={1,0}\n  call.83 = f32[] call(transpose.68), to_apply=det_2.69\n  multiply.84 = f32[] multiply(call.83, constant.2)\n  add.85 = f32[] add(add.64, multiply.84)\n  slice.86 = s32[1,2]{1,0} slice(Arg_0.1), slice={[4:5], [0:2]}\n  slice.87 = s32[1,2]{1,0} slice(Arg_0.1), slice={[0:1], [0:2]}\n  concatenate.88 = s32[2,2]{1,0} concatenate(slice.86, slice.87), dimensions={0}\n  transpose.89 = s32[2,2]{0,1} transpose(concatenate.88), dimensions={1,0}\n  call.104 = f32[] call(transpose.89), to_apply=det_3.90\n  multiply.105 = f32[] multiply(call.104, constant.2)\n  add.106 = f32[] add(add.85, multiply.105)\n  ROOT tuple.107 = (f32[]) tuple(add.106)\n}\n\n\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#Could-We-Jit-Anything?}

### Could We Jit Anything?

Absolutely not, please check [this documentation](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html#why-can-t-we-just-jit-everything) from JAX!

The most common cause to unjittable program is your control flow relies on the value of <strong>input</strong>. For instance,

<Notebook.Cell>
  <Notebook.CodeArea prompt="[9]:" stderr={false} type="input">
    ```python
    # Cited from JAX documentation.
    # While loop conditioned on x and n.


    def g(x, n):
        i = 0
        while i < n:
            i += 1
        return x + i


    g_jit = jax.jit(g)

    import traceback

    try:
        g_jit(10, 20)  # Should raise an error.
    except Exception:
        traceback.print_exc()
    ```
  </Notebook.CodeArea>
</Notebook.Cell>

There are two possible solutions. 1. You could replace control flow with [low-level jax.lax APIs](https://jax.readthedocs.io/en/latest/jax.lax.html#control-flow-operators). You need to spend some time figure out how to use these APIs.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[10]:" stderr={false} type="input">
    ```python
    def g_with_lax_control_flow(x, n):
        def body_fun(i):
            i += 1
            return i

        return x + jax.lax.while_loop(lambda i: i < n, body_fun, 0)


    g_with_lax_control_flow_jit = jax.jit(g_with_lax_control_flow)
    g_with_lax_control_flow_jit(10, 20)  # good to go!
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[10]:" stderr={false} type="output">
    <pre>
      {"Array(30, dtype=int32, weak_type=True)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

2. The other possible solution is to use <strong>static\_argnames</strong>.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[11]:" stderr={false} type="input">
    ```python
    g_with_static_argnames_jit = jax.jit(g, static_argnames=['n'])
    g_with_static_argnames_jit(10, 20)  # good to go!
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[11]:" stderr={false} type="output">
    <pre>
      {"Array(30, dtype=int32, weak_type=True)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

so which method we should choose when the program is unjittable?

This is our suggestion:

- Rewrite the control flow with <strong>jax.lax</strong> APIs first. Although these are some learning costs here, but it deserves that.
- If the visibility of affected input values are <strong>VIS\_PUBLIC</strong> like <strong>n</strong> in the above example, you could mark it as <strong>static\_argnames</strong> and these affected input values would be compiled into XLA program.

:target{#More-Examples}

### More Examples

If you would like to check more examples, please check [Python examples](https://github.com/secretflow/spu/tree/main/examples/python) in SPU repo. In most examples, the MPC part are written with <strong>jax.numpy</strong> package. And you could find we are using <strong>jax.lax</strong> APIs and <strong>static\_argnames</strong> heavily to make JAX program jittable!

:target{#Execute-JAX-Program-with-SPU}

## Execute JAX Program with SPU

Once you have your jittable JAX program ready, we could execute them with SPU!

:target{#(Optional)-SPU-Simulation}

### (Optional) SPU Simulation

If you hope to get a quick try, I would like to introduce <strong>spu.sim\_jax</strong> to you. Let’s show how does it work!

> <strong>spu.sim\_jax</strong> is only exposed after <strong>spu v0.3.1b8</strong>.

Here we create an SPU simulator with the following settings: - world size of 3. - with ABY3 protocol. Check all supported protocol [here](http://www.secretflow.org.cn/docs/spu/en/reference/mpc_status.html#supported-mpc-protocol). - field of 64 which the values in SPU are expressed in 2^64 ring.

However, if you just want to confirm if the JAX program could be executed by SPU, any settings should be fine. Different settings could only affect the elapsed time and precision of computation.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[12]:" stderr={false} type="input">
    ```python
    from spu.utils.simulation import Simulator, sim_jax

    sim = Simulator.simple(3, spu.ProtocolKind.ABY3, spu.FieldType.FM64)

    spu_euclidean_distance_fn = sim_jax(sim, euclidean_distance)

    spu_euclidean_distance_fn(np.array([0, 0]), np.array([3, 4]))
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[12]:" stderr={false} type="output">
    <pre>
      {"array(4.999962, dtype=float32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

If you execute the code above repeatedly, you may find the result is slightly different between runs, which is expected due to randomness in MPC computation.

After testing with <strong>euclidean\_distance</strong>, we have a try with <strong>area\_of\_simple\_polygon</strong>.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[13]:" stderr={false} type="input">
    ```python
    spu_area_of_simple_polygon_fn = sim_jax(sim, area_of_simple_polygon)

    spu_area_of_simple_polygon_fn(vertices)
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[13]:" stderr={false} type="output">
    <pre>
      {"array(16.5, dtype=float32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#Run-with-SPU-Device}

### Run with SPU Device

Finally, we are going to run the JAX program with SecretFlow.

I guess you should be familiar with the following steps if you have checked out other tutorials.

Here we create a local standalone SecretFlow cluster with three devices:

- Two PYU device - <strong>alice</strong> and <strong>bob</strong>
- An SPU device

<Notebook.Cell>
  <Notebook.CodeArea prompt="[14]:" stderr={false} type="input">
    ```python
    import secretflow as sf

    # Check the version of your SecretFlow
    print('The version of SecretFlow: {}'.format(sf.__version__))

    # In case you have a running secretflow runtime already.
    sf.shutdown()

    sf.init(parties=['alice', 'bob'], address='local')

    alice, bob = sf.PYU('alice'), sf.PYU('bob')
    spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))
    ```
  </Notebook.CodeArea>
</Notebook.Cell>

We try <strong>euclidean\_distance</strong> with spu device first.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[15]:" stderr={false} type="input">
    ```python
    p1 = sf.to(alice, np.array([0, 0]))
    p2 = sf.to(bob, np.array([3, 4]))

    distance = spu(euclidean_distance)(p1, p2)

    sf.reveal(distance)
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[15]:" stderr={false} type="output">
    <pre>
      {"array(5., dtype=float32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

Then we try <strong>area\_of\_simple\_polygon</strong>.

<Notebook.Cell>
  <Notebook.CodeArea prompt="[16]:" stderr={false} type="input">
    ```python
    v = sf.to(alice, vertices)
    area = spu(area_of_simple_polygon)(v)

    sf.reveal(area)
    ```
  </Notebook.CodeArea>

  <Notebook.CodeArea prompt="[16]:" stderr={false} type="output">
    <pre>
      {"array(16.5, dtype=float32)\n"}
    </pre>
  </Notebook.CodeArea>
</Notebook.Cell>

:target{#Summary}

## Summary

This is the end of the tutorial. Let’s summarize the steps to do privacy-preserving scientific computation with JAX NumPy APIS:

1. Write a jittable JAX NumPy program. You should test it with <strong>jax.jit</strong> or <strong>jax.xla\_computation</strong>.
2. (Optional) Try the JAX program with <strong>SPU simulation</strong>.
3. Run this JAX NumPy with SPU device in SecretFlow.

If you find your JAX program is jittable but fails with SPU compiler or runtime. Please check [JAX NumPy Operators Status](http://www.secretflow.org.cn/docs/spu/en/reference/np_op_status.html) and [XLA Implementation Status](http://www.secretflow.org.cn/docs/spu/en/reference/xla_status.html). Or you could contact us directly with [GitHub Issues](https://github.com/secretflow/spu/issues).
